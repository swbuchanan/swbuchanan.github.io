<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Steven&#39;s website</title>
    <link>http://localhost:1313/swbuchanan.github.io/posts/</link>
    <description>Recent content in Posts on Steven&#39;s website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Thu, 11 Dec 2025 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/swbuchanan.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Nagel-Schreckenberg traffic simulation</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/traffic_simulation/</link>
      <pubDate>Thu, 11 Dec 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/traffic_simulation/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;https://artowen.su.domains/mc/Ch-intro.pdf&#34;&gt;this&lt;/a&gt; text book available online about Monte Carlo simulation, the first example given is a traffic simulation that shows how traffic jams can emerge seemingly out of nowhere, even when there aren&amp;rsquo;t any particularly bad drivers or disruptive incidents on the road.
Below is a small demonstration of traffic following the &lt;strong&gt;Nagel-Schreckenberg&lt;/strong&gt; simulation rules.
Based on these rules, we have the following setup:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The road is divided into discrete cells, each with one car.&lt;/li&gt;
&lt;li&gt;The cars all have some velocity $v$.&lt;/li&gt;
&lt;li&gt;There is a maximum velocity $v_{\max}$ that all cars obey.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The simulation proceeds in discrete time steps.
At each time step, the following 4 rules are applied to all cars in parallel.
For each car,&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;If its velocity is below $v_{\max}$, it increases its velocity by one unit.&lt;/li&gt;
&lt;li&gt;It checks the distance to the car in front of it.&lt;/li&gt;
&lt;li&gt;If that distance is $d$ spaces and the car has velocity $v \geq d$, then it reduces its velocity to $d-1$ in order to avoid collision.&lt;/li&gt;
&lt;li&gt;If the velocity is positive then with probability $p$ it reduces its velocity by 1 unit. This is the key step that models random driver behavior.&lt;/li&gt;
&lt;li&gt;The motion of the car takes place. That is, the car moves ahead by $v$ units.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here is a simulation following these rules with a road that wraps around (so the drivers are effectively driving in a circle).
The road has length 700, there are 100 drivers, and the probability of braking is around $1/3$.
The maximum speed is 3.&lt;/p&gt;
&lt;!DOCTYPE html&gt;
&lt;html lang=&#34;en&#34;&gt;
&lt;head&gt;
  &lt;meta charset=&#34;UTF-8&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;
  &lt;title&gt;Canvas Curve&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;canvas id=&#34;trafficCanvas&#34; style=&#34;width: 100%; border:0px solid #000000;&#34;&gt;&lt;/canvas&gt;
  &lt;script src=&#34;http://localhost:1313/swbuchanan.github.io/js/traffic_simulation.js&#34;&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;


&lt;p&gt;I made this in a hurry but soon I hope to update this page with options to adjust the number of drivers, the maximum speed, and the probability $p$ of braking.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Detecting 4-cycles in a graph is easier than detecting triangles</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/graph-cycle-detection/</link>
      <pubDate>Mon, 01 Dec 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/graph-cycle-detection/</guid>
      <description>&lt;h2 id=&#34;an-algorithm-to-detect-triangles-in-a-graph&#34;&gt;An algorithm to detect triangles in a graph&lt;/h2&gt;
&lt;p&gt;Recently I was looking through &lt;a href=&#34;https://kam.mff.cuni.cz/~matousek/stml-53-matousek-1.pdf&#34;&gt;Thirty-three Miniatures: Mathematical and Algorithmic Applications of Linear Algebra&lt;/a&gt;.
One of the applications is an algorithm to efficiently detect a triangle in a graph, such as the following.
(There is an obvious algorithm that works by enumerating all possible triplets of vertices and checking them one at a time; this involves some multiple of $n^3$ steps, where $n$ is the number of vertices.
That is, the algorithm has $O(n^3)$ time complexity, which is really bad.)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/swbuchanan.github.io/graph_example.png&#34; alt=&#34;a graph with a triangle highlighted&#34;&gt;&lt;/p&gt;
&lt;p&gt;The algorithm works in the following way.
Construct the adjacency matrix of the graph.
This is done by labeling the vertices with numbers $1, 2, \dots, v$, where $v$ is the number of vertices.
Then, the entry in row $i$, column $j$ of the matrix is $1$ if there is an edge between vertex $i$ and vertex $j$, and 0 otherwise.
This gives us a matrix that encodes exactly the same information as the &amp;ldquo;dots and lines&amp;rdquo; representation of a graph.
For example, this graph:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;http://localhost:1313/swbuchanan.github.io/graph_example_2.png&#34; alt=&#34;a graph with labeled vertices&#34;&gt;&lt;/p&gt;
&lt;p&gt;has adjacency matrix
$
\begin{bmatrix}
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 \\
1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 \\
0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0
\end{bmatrix}.
$&lt;/p&gt;
&lt;p&gt;For the graph where we want to find triangles, call its adjacency matrix $A$.
Now the key is to consider the square of this matrix, $A^2$.
By definition of matrix multiplication, the entry in row $i$, column $j$ of this matrix will be (here $a_{m, n}$ denotes the entry in row $m$, column $n$ of matrix $A$)
$$
b_{i,j} = a_{i,1} a_{1,j} + a_{i, 2} a_{2,j} + \cdots + a_{i, v} a_{v, j}.
$$
Note that&lt;/p&gt;
&lt;p&gt;$$
a_{i,k}a_{k,j} =
\begin{cases}
1 &amp;amp; \text{if the vertex $k$ is adjacent to both $i$ and $j$}, \\
0 &amp;amp; \text{otherwise,}
\end{cases}
$$
from which it follows that $b_{i,j}$ is the number of neighbors that are common to vertex $i$ and vertex $j$.
We&amp;rsquo;re almost done.
To find a triangle, we just have to find a pair of vertices that are connected to each other and have a common neighbor.
With the matrices that we&amp;rsquo;ve constructed, this amounts to finding some values for $i$ and $j$ for which both&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$a_{i,j} \neq 0$ (meaning that $i$ and $j$ are connected to each other) and&lt;/li&gt;
&lt;li&gt;$b_{i,j} \neq 0$ (meaning that $i$ and $j$ have a common neighbor.
Thus we merely have to inspect the  matrices $A$, $A^2$ to find the triangle.
To summarize, our algorithm goes like this:&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;Construct the adjacency matrix for the graph.&lt;/li&gt;
&lt;li&gt;Square the adjacency matrix.&lt;/li&gt;
&lt;li&gt;Compare the adjacency matrix with its square to see if there are nonzero entries in matching cells.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The complexity bottleneck in this algorithm is in the second step.
Currently it is conjectured but not proven that matrix multiplication can be done by an algorithm with $O(n^2)$ steps.
The algorithm that is used most often in practice (Strassen&amp;rsquo;s algorithm) has complexity around $O(n^{2.807})$.
The best theoretical bound is $O(n^{2.371339})$, but this and other &amp;ldquo;improvements&amp;rdquo; on Strassen&amp;rsquo;s algorithm are not used in practice since the constants hidden by the big-O notation are impractically large for the size of matrices that current computers can deal with.
In any case, we can safely say that our algorithm to detect triangles is significantly worse than $O(n^2)$.&lt;/p&gt;
&lt;h2 id=&#34;an-algorithm-to-detect-4-cycles-in-a-graph&#34;&gt;An algorithm to detect 4-cycles in a graph&lt;/h2&gt;
&lt;p&gt;This is a case where a more complicated problem actually has a simpler solution.
A triangle in a graph is also called a 3-cycle, since it is 3 vertices that form a closed loop.
Similarly, we can ask about the existence of 4 vertices in a closed loop.&lt;/p&gt;
&lt;p&gt;There is a very straightforward algorithm to check for 4-cycles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;enumerate through all pairs of vertices $u$ and $v$ (this is $O(n^2)$)&lt;/li&gt;
&lt;li&gt;compute the vertices that $u$ and $v$ have in common (this is $O(n^2)$ or better)&lt;/li&gt;
&lt;li&gt;if the set of common vertices ever contains more than one element, we have found the 4-cycle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So we see that this seemingly more complex problem is strictly easier, requiring only $O(n^2)$ steps.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://drops.dagstuhl.de/storage/00lipics/lipics-vol284-fsttcs2023/LIPIcs.FSTTCS.2023.25/LIPIcs.FSTTCS.2023.25.pdf?&#34;&gt;Abboud, Khoury, Leibowitz, Safier - Listing 4-cycles&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://kam.mff.cuni.cz/~matousek/stml-53-matousek-1.pdf&#34;&gt;Thirty-three Miniatures: Mathematical and Algorithmic Applications of Linear Algebra&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>A project on implied probability density functions for asset prices</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/implied_stock_distributions/</link>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/implied_stock_distributions/</guid>
      <description>&lt;p&gt;I recently completed a project for an online course in computational quant finance.
The project is about how to derive a certain probability density function for an asset at a date in the future by looking at options that expire on that date.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://nbviewer.org/github/swbuchanan/implied-stock-distributions/blob/main/project.ipynb&#34;&gt;View the project notebook on nbviewer.&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to tell if a 15-type puzzle is solvable</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/fifteen-puzzle/</link>
      <pubDate>Sun, 22 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/fifteen-puzzle/</guid>
      <description>&lt;p&gt;I want to have a highly responsive adjustable 15-type puzzle game with timing and leaderboards.
In order to do this, I need to be able to generate random starting positions for the board.
However, an interesting fact about the 15 puzzle is that not all possible arrangements of the $15$ tiles on the $16 \times 16$ grid are solvable.
For example, if one takes the starting arrangement and swaps the 14 and 15 only, the resulting arrangement cannot be solved with normal moves (i.e. without doing some swap of two other tiles).
This would also be true for the starting arrangement with any two adjacent tiles swapped with each other.&lt;/p&gt;
&lt;p&gt;So, my problem is to generate random starting positions, but check in some way that I don&amp;rsquo;t present the player with an unsolvable configuration.
One possible solution to this problem is to not just generate a random configuration, but to generate a random sequence of moves from the starting position.
This is what one would do with a physical puzzle to &amp;ldquo;randomize&amp;rdquo; it, assuming that the pieces are not allowed to be removed from the board; just make moves without paying close attention and without any pattern.
This is actually a fine solution, it just doesn&amp;rsquo;t appeal to my mathematical sensibilities.
What I would like is a straightforward way to take a random position and check if it is solvable or not.&lt;/p&gt;
&lt;p&gt;Fortunately for me this problem has already been solved.
Here I&amp;rsquo;ll explain the method I&amp;rsquo;ll use.&lt;/p&gt;
&lt;!DOCTYPE html&gt;
&lt;html lang=&#34;en&#34;&gt;
&lt;head&gt;
  &lt;meta charset=&#34;UTF-8&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;
  &lt;title&gt;Fifteen game&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;canvas id=&#34;gameCanvas&#34; width=&#34;200&#34; height=&#34;200&#34; tabindex=&#34;0&#34; style=&#34;margin:20px auto;border:1px solid #000000;display:block&#34;&gt;&lt;/canvas&gt;
  &lt;button id=&#34;restartGame&#34;&gt;Reestart&lt;/button&gt;
  &lt;label&gt;
      &lt;input type=&#34;checkbox&#34; id=&#34;reverseToggle&#34;&gt;
      Reverse controls
  &lt;/label&gt;
    &lt;/div&gt;
    &lt;div id=&#34;game-config&#34;
        data-size=&#34;&#34;
        data-default-setup=&#34;&#34;&gt;
    &lt;/div&gt;

  &lt;script src=&#34;http://localhost:1313/swbuchanan.github.io/js/fifteen.js&#34;&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;


&lt;p&gt;what&lt;/p&gt;
&lt;p&gt;here is another thingy&lt;/p&gt;
&lt;!doctype html&gt;
&lt;html lang=&#34;en&#34;&gt;
  &lt;head&gt;
    &lt;meta charset=&#34;utf-8&#34; /&gt;
    &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width,initial-scale=1&#34; /&gt;
    &lt;title&gt;Penney&#39;s Game (Canvas)&lt;/title&gt;
    &lt;style&gt;
      html, body { height: 100%; margin: 0; background:#111; color:#ddd; font: 14px/1.4 system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; }
      .wrap { display:flex; align-items:center; justify-content:center; height:100%; }
      canvas { border: 1px solid #333; background:#0d0d0d; }
      .tip { position:fixed; bottom:10px; width:100%; text-align:center; color:#777; font-size:12px; }
    &lt;/style&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;div class=&#34;wrap&#34;&gt;
      &lt;canvas id=&#34;penneyGame&#34; width=&#34;760&#34; height=&#34;280&#34; aria-label=&#34;Penney&#39;s game&#34;&gt;&lt;/canvas&gt;
    &lt;/div&gt;
    &lt;div class=&#34;tip&#34;&gt;Click the three tiles to toggle H/T. Then click Play.&lt;/div&gt;
    
    &lt;script src=&#34;http://localhost:1313/swbuchanan.github.io/js/penney.js&#34;&gt;&lt;/script&gt;
  &lt;/body&gt;
&lt;/html&gt;

&lt;!DOCTYPE html&gt;
&lt;html lang=&#34;en&#34;&gt;
&lt;head&gt;
  &lt;meta charset=&#34;UTF-8&#34;&gt;
  &lt;meta name=&#34;viewport&#34; content=&#34;width=device-width, initial-scale=1.0&#34;&gt;
  &lt;title&gt;Fifteen game&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
    &lt;div style=&#34;text-align: center;&#34;&gt;
  &lt;canvas id=&#34;gameCanvas&#34; width=&#34;200&#34; height=&#34;200&#34; tabindex=&#34;0&#34; style=&#34;margin:20px auto;border:1px solid #000000;display:block&#34;&gt;&lt;/canvas&gt;
  &lt;button id=&#34;restartGame&#34;&gt;Reestart&lt;/button&gt;
  &lt;label&gt;
      &lt;input type=&#34;checkbox&#34; id=&#34;reverseToggle&#34;&gt;
      Reverse controls
  &lt;/label&gt;
    &lt;/div&gt;
    &lt;div id=&#34;game-config&#34;
        data-size=&#34;4&#34;
        data-default-setup=&#34;true&#34;&gt;
    &lt;/div&gt;

  &lt;script src=&#34;http://localhost:1313/swbuchanan.github.io/js/fifteen.js&#34;&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;


</description>
    </item>
    
    <item>
      <title>An unintuitive fact about random drawings with and without replacement</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/an_unintuitive_fact_about_drawing_with_replacement/</link>
      <pubDate>Fri, 13 Jun 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/an_unintuitive_fact_about_drawing_with_replacement/</guid>
      <description>&lt;p&gt;Here&amp;rsquo;s an odd fact that I came across while doing a probability puzzle.
I&amp;rsquo;ll start by presenting a version of this puzzle; I hope you have the patience to try it yourself, at least for a minute or two.
I&amp;rsquo;ll present it in two parts.
The first part is relatively easy.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Suppose you are going to draw 10 cards from a standard 52-card shuffled deck of playing cards.
You are drawing with replacement, meaning that after each card is drawn, you note what it is and replace it back into the deck and shuffle again before the next draw.
What is the expected number of aces that you draw during this process?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To solve this, all we have to do is calculate the expected number of aces in a single round of this game, and then multiply that number by 10.
This is because each round is identical to the previous round.
Since $4/52$ cards in the deck are aces, the probability of drawing an ace in a single draw is $4/52 = 1/13$.
Thus on average, in each round of this game we expect to draw one thirteenth of an ace.
Or, if we play this game for 10 rounds, on average we will end up drawing $10/13 \approx .77$ aces.&lt;/p&gt;
&lt;p&gt;To be slightly more technical, we are using the fact that expectation is linear.
If $X$ is a random variable that measures how many aces we draw, and $X_i$ is a random variable that measures how many aces we draw in round $i$, then $X = X_1 + \cdots + X_{10}$.
Then using linearity of expectation,
$$E[X] = E[X_1 + \cdots + X_{10}] = E[X_1] + \cdots + E[X_{10}].$$&lt;/p&gt;
&lt;p&gt;So we see that it is sufficient to calculate the expectation for each round, as we have done.&lt;/p&gt;
&lt;p&gt;So far so good.
Now we proceed to a harder version of the problem.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In this version of the game, we don&amp;rsquo;t replace the cards after each round.
If you draw 10 cards without replacement, what is the expected number of aces that you will draw?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;We can&amp;rsquo;t use the same idea as before; after all, not every round of this game needs to be the same.
If our first draw happens to be an ace, then the probability of drawing an ace in the future rounds goes down.
Alternatively, each time we draw a card that is not an ace, the probability of drawing an ace in the next round goes up slightly.
A further confusion is that the expectation in the previous version has to account for the fact that in some scenarios we could draw more than 4 aces.
In this version where we draw without replacement, it&amp;rsquo;s clear that we can&amp;rsquo;t draw any more than 4.&lt;/p&gt;
&lt;p&gt;But now we get to our unintuitive fact - despite all these considerations, the expected number of aces when we&amp;rsquo;re drawing without replacement is exactly the same as the expected number when drawing with replacement.&lt;/p&gt;
&lt;p&gt;One way to justify this is as follows.
We&amp;rsquo;ll use exactly the same fact that expectation is linear, but we need to choose our random variables slightly more cleverly.&lt;/p&gt;
&lt;p&gt;Let $X_s$ denote the number of times that we draw the ace of spaces.
Similarly, let $X_c, X_h, X_d$ denote respectively the number of times that we draw the ace of clubs, hearts, and diamonds.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Now if $X$ is the total number of aces that we have among the 10-card hand that we draw, then $X = X_s + X_c + X_h + X_d$, and so we again have that
$$E[X] = E[X_s] + E[X_c] + E[X_h] + E[X_d].$$&lt;/p&gt;
&lt;p&gt;Since no ace is more likely to be drawn than any other, if we find the expected number of times that the ace of spades is among the 10 cards we draw, then we are essentially done.
In this case, $X_s = 1$ with probability $P_s$, and $X_s = 0$ with the remaining probability $1 - P_s$, where $P_s$ is the probability that the ace of spades is among the 10 cards that we draw.
This means that $X_s = P_s.$
This probability is easy to calculate; it&amp;rsquo;s just $10/52$.
The chances of a particular card being in some randomly selected portion of the deck is just equal to the exact proportion that we select.
Now, we see that indeed we get the same answer,&lt;/p&gt;
&lt;p&gt;$$E[X] = 4 \cdot E[X_s] = 4 \cdot \frac{10}{52} = \frac{10}{13}. \phantom{\frac{\hat{1}}{0}}$$&lt;/p&gt;
&lt;p&gt;Now the exercise for the reader is to use this idea to trick someone at the bar and make some money.&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;One may object that these numbers depend on each other when we&amp;rsquo;re drawing without replacement; this is related to the complications we mentioned that seem to arise when going from drawing with replacement to drawing without replacement.
Fortunately, the linearity of expectation does not require the random variables to be independent.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Running every street in Canberra</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/running-canberra/</link>
      <pubDate>Fri, 02 May 2025 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/running-canberra/</guid>
      <description>&lt;p&gt;Inspired by &lt;a href=&#34;pac.tom7.org/index.shtml&#34;&gt;this guy&lt;/a&gt;, who also has a great &lt;a href=&#34;https://www.youtube.com/watch?v=1c8i5SABqwU&#34;&gt;youtube channel&lt;/a&gt;, I have recently decided to run the length of every street in Canberra, where I&amp;rsquo;m currently staying for school.
Soon I hope to update this page with some rules for the project and some information about how I&amp;rsquo;m gathering and processing the data.
For now, &lt;a href=&#34;http://localhost:1313/swbuchanan.github.io/all_routes.html&#34;&gt;here&amp;rsquo;s my current progress&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This project has been put on hold as I am now living in Canada until February 2026.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Some mathematical questions about Tetris</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/mathematical-tetris-questions/</link>
      <pubDate>Fri, 11 Apr 2025 23:20:32 +1100</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/mathematical-tetris-questions/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://jstris.jezevec10.com/&#34;&gt;https://jstris.jezevec10.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Tetris is pretty fun.
In case anyone reading this needs some introduction to the game, see the link.
The oldest published mathematical analysis I could find of this game is in a master&amp;rsquo;s thesis from 1992 by John Brzustowski at the University of British Columbia.
See here
&lt;a href=&#34;https://open.library.ubc.ca/media/stream/pdf/831/1.0079748/1&#34;&gt;https://open.library.ubc.ca/media/stream/pdf/831/1.0079748/1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The thesis answers the question of whether or not it&amp;rsquo;s possible for a game of Tetris to go on indefinitely.
Of course a slightly idealized version of the game is examined in the mathematical analysis; for example we don&amp;rsquo;t consider the time that it takes to place the piece.
In the arcade version of the game, the speed of the pieces increases as the game progresses and the game gets more difficult.
It seems natural to ignore this part of the game&lt;/p&gt;
&lt;p&gt;However, in many versions of Tetris, there are some features that enable one to play indefinitely, with a reasonably simple strategy.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://harddrop.com/wiki/Playing_forever&#34;&gt;https://harddrop.com/wiki/Playing_forever&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A stupid application of the Kelly Criterion</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/kelly-criterion-backgammon/</link>
      <pubDate>Fri, 21 Mar 2025 23:20:32 +1100</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/kelly-criterion-backgammon/</guid>
      <description>&lt;p&gt;The Kelly Criterion is a classic solution to a classic problem.
Suppose I give you 100 dollars and an unfair coin.
The coin lands on heads 60% of the time, but I&amp;rsquo;ll bet you even money that it lands on tails.
If I tell you that I&amp;rsquo;ll offer you this bet 1000 times, and you can bet as much of your bankroll as you want, what is your best way of making money?
(Your bankroll is the 100 dollars that you started with together with any money that you win by betting against me.)
On each bet, you can maximize your expected profit by betting all of your bankroll.
However, this leaves open the possibility of losing all your money.&lt;/p&gt;
&lt;p&gt;I recently started playing backgammon online.
This game has a lot to recommend it; it is a highly strategic game of perfect information (according to some definitions) with some random chance involved.
I&amp;rsquo;m not sure&lt;/p&gt;
&lt;p&gt;In order to calculate my chances of winning, I would need to know about about some variables that are essentially unknowable.
Backgammon Galaxy has a rating system; I assume that it tries to pair each player with another player of the same level.
If it could successfully do this every time, each player would have a 50% chance of winning every game.
Actually this is not quite true; a player that is in the process of improving would always be slightly underrated and thus have a slighly greater than 50% chance of winning.
There is another complication: based on my experience over a few dozen games or so, it seems like if you rating is too low, you are likely to be ranked against a higher rated player.&lt;/p&gt;
&lt;p&gt;In order for the Kelly Criterion to apply, my chance of winning can&amp;rsquo;t be too low.
Note that for the classic Kelly problem, if one is making even bets with a chance of winning that is less than 50%, the Kelly Criterion tells you that the best way to make money is to bet nothing, so I would be better off not playing!
There is a confounding factor for me: the website gives you some rewards just for playing games, as well as some rewards for checking in to the site.
I&amp;rsquo;ll try to factor these in to get as realistic a model as possible.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s also not the case that we make even bets on the website; players are able to buy coins with real money, and to encourage them to do so, some coins are raked from every match.
In particular, the winning player is returned the coins that he staked for the game plus 85% of the losing players stake.
That is, 15% of one bet is removed from the coin pool every game (TODO: I know this is true for 100-coin stake games, but what about higher?).&lt;/p&gt;
&lt;p&gt;So I need to consider the following things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;My winning chances given current distribution of ratings and my place in it,&lt;/li&gt;
&lt;li&gt;The rewards I get for playing a certain number of games, as well as the amount I&amp;rsquo;m winning/losing by playing these games,&lt;/li&gt;
&lt;li&gt;The rewards I get for checking into the site without necessarily playing any games,&lt;/li&gt;
&lt;li&gt;The coins that are raked from the site.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first challenge is to determine the distribution of ratings.
Unlike lichess, backgammongalaxy does not publish much data about&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A cute proof of Weierstrass approximation</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/weierstrass-approximation/</link>
      <pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/weierstrass-approximation/</guid>
      <description>&lt;p&gt;The Weierstrass approximation theorem says that (on an interval of finite length) we can approximate any continuous function arbitrarily well by polynomials.
As polynomials have very nice mathematical and computational properties, this is a very useful theorem.&lt;/p&gt;
&lt;p&gt;Probably most people who have encountered any proof of the Weierstrass approximation theorem have already seen the essential idea of this proof.
Indeed, this is basically the original proof that Karl Weierstrass gave in 1885, just with a slightly different perspective.
The idea of the proof is to take $f(x)$, the function that we are trying to approximate, as initial data to the heat equation.
Then allow the heat distribution described by $f$ to diffuse for a very short amount of time.
The heat equation has the remarkable property that its solutions immediately become smooth.
But if we only allow the diffusion to happen for a sufficiently short amount of time, the distribution after this short time is still quite close (in the appropriate sense of &amp;ldquo;close&amp;rdquo;) to the original function $f$.
Thus we have a smooth approximation.
From there we can use Taylor&amp;rsquo;s theorem, which says that a smooth function can be approximated by polynomials.&lt;/p&gt;
&lt;p&gt;To be more precise, we can find a function $\phi(x,t)$ so that $\phi(x,t)$ is a solution to the heat equation on $\R \times (0, \infty)$ with $\phi(x,0) = f(x)$.
Then $\phi$ converges uniformly to $f$ as $t$ goes backwards to $0$, and the function $\phi(\cdot, t)$ is smooth for all fixed $t &amp;gt; 0$.
Since $\phi$ is smooth, we can apply Taylor&amp;rsquo;s theorem to obtain the uniform approximation by polynomials.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Theorem: Weierstrass approximation. Given a continuous compactly supported function $f$ on $\R$ and $\epsilon &amp;gt; 0$, there is a polynomial $p(x)$ such that $|f(x) - p(x)| &amp;lt; \epsilon$ for all $x \in \R$.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Proof. Take
$$\phi(x,t) = \frac{1}{\sqrt{4 \pi t}} \int_{\R} e^{-\frac{(x-y)^2}{4t}} f(y) \, dy.$$
This is the convolution of $f$ with the Gaussian heat kernel, and thus is the unique solution of the heat equation with initial data $f$.
By differentiating under the integral sign, we can see that all derivatives exist and are continuous.
The fact that $\phi(x,t) \to f(x)$ uniformly also follows from properties of the Gaussian heat kernel.
In particular, as $t \to 0$ from above, the kernel approximates a Dirac delta centered at $x$.
This means that the integral converges to $f(x)$.&lt;/p&gt;
&lt;p&gt;So, given $\epsilon &amp;gt; 0$, choose $t_0$ small enough that
$$|\phi(x,t_0) - f(x)| &amp;lt; \frac{\epsilon}{2}$$
for all $x$.
Now since $\phi(\cdot, t_0)$ is smooth on the compact support of $f$, it follows from Taylor&amp;rsquo;s theorem that there is a polynomial $p(x)$ such that
$$|\phi(x,t_0) - p(x)| &amp;lt; \frac{\epsilon}{2}$$
for all $x$.
Now by the triangle inequality,
$$|f(x) - p(x)| \leq |f(x) - \phi(x, t_0)| + |\phi(x,t_0) - p(x)| &amp;lt; \epsilon,$$
and we have our approximation.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Ancient 2-dimensional solutions to the Ricci flow</title>
      <link>http://localhost:1313/swbuchanan.github.io/posts/ancient-solutions/</link>
      <pubDate>Fri, 23 Aug 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/swbuchanan.github.io/posts/ancient-solutions/</guid>
      <description>&lt;p&gt;Here I&amp;rsquo;ll give a more technical description of the work that I&amp;rsquo;m doing.
See my other posts for a generally accessible version of the same thing.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Geometric evolution equations describe how some quantity defined on a manifold changes over time.
This is a broad idea; it applies to the description of many evolving physical systems, and for many years has allowed us to apply the theory of partial differential equations to these problems.
Solutions of certain equations provide geometric models for corresponding physical phenomena.
The shape of a stationary film of soap is the solution to an elliptic partial differential equation.
The heat equation,
$$\frac{\partial}{\partial t} u = \Delta u,$$
which describes diffusion processes like heat spreading through an unevenly heated object, is the prototypical parabolic partial differential equation.&lt;/p&gt;
&lt;p&gt;Recently many differential equations and systems of equations - particularly parabolic systems - have been used to describe certain natural deformations of curves, surfaces, or Riemannian metrics (among other geometric objects).
Aside from direct physical applications, these theories can be applied to the problem of finding canonical or &amp;ldquo;best&amp;rdquo; metrics on Riemannian manifolds.&lt;/p&gt;
&lt;h2 id=&#34;the-ricci-flow&#34;&gt;The Ricci Flow&lt;/h2&gt;
&lt;p&gt;The pioneering work in this direction was by Richard Hamilton in 1982.
Motivated by the work of Eells and Sampson on the harmonic map heat flow (a way of deforming arbitrary maps between manifolds into harmonic maps), Hamilton considered a &amp;ldquo;heat equation&amp;rdquo; for the metric of a Riemannian manifold.&lt;/p&gt;
&lt;p&gt;Hamilton classified all compact 3-manifolds of positive Ricci curvature by showing that, given an arbitrary Riemannian metric with positive Ricci curvature on a 3-manifold, the metric could smoothly deform to have constant curvature.
In particular, he examined the following.
Given a (compact) manifold $M$, a one-parameter family $g_t$ of Riemannian metrics on $M$ is said to evolve by the Ricci flow if
$$\frac{\partial}{\partial t} g_{ij} = R_{ij}$$
where $R$ is the Ricci curvature of $g(t)$.
This turns out to be a weakly parabolic system of nonlinear partial differential equations.
In particular, in the proper coordinates, this equation becomes
$$ \frac{\partial}{\partial t}g_{ij} = \Delta g_{ij} + \text{lower order terms.}  $$
The Ricci flow equation shares some important properties with the heat equation, and many other geometric quanities, including the Riemann curvature tensor, satisfy similar heat-type equations as the metric.
To such quantities we can often apply the &lt;em&gt;maximum principle&lt;/em&gt;, a far-reaching generalization of the fact that at a local maximum of a function $u(x,t)$ satisfying $u_t = u_{xx}$, the second derivative of $u$ will be negative, and thus $u_t &amp;lt; 0$, causing the maximum of $u$ to decrease over time.&lt;/p&gt;
&lt;p&gt;One example to keep in mind is the &lt;em&gt;shrinking sphere&lt;/em&gt;.
A sphere has the same positive curvature everywhere.
Since the curvature is positive, the right hand side of the Ricci flow equation is negative, so the Ricci flow will uniformly shrink the metric.
A natural question then is what happens to the flow as the sphere shrinks down to a point.
This question and related questions form the topic of singularity analysis within the study of geometric flows.&lt;/p&gt;
&lt;h2 id=&#34;modeling-singularities&#34;&gt;Modeling singularities&lt;/h2&gt;
&lt;p&gt;Suppose we have a solution to the Ricci flow with finite maximal time of existence $T$.
Then at $t \to T$, the curvature of the metric goes to infinity somewhere on the manifold (or indeed everywhere, as in the case of the sphere).
The technique we use to deal with this situation is to choose a sequence of times $t_i \to T$ and a sequence of points $x_i$ converging to the point where the curvature is exploding (e.g. the points where the supremum of curvature up to time $t_i$ is attained on $M$).
Then we apply a parabolic rescaling
$$ g_\lambda(x,t) = \lambda^2 g \left( x, \frac{t}{\lambda^2} \right) $$
so that the curvature remains bounded.
It is a general property of the Ricci flow that a parabolically rescaled solution to the flow is another solution.
Assuming a lower bound on the injectivity radius, there is a compactness theorem for solutions to the Ricci flow that ensures we can take a (subsequential) limit and obtain a so-called ancient solution to the Ricci flow that tells us what the manifold looks like near the singularity.&lt;/p&gt;
&lt;h2 id=&#34;ancient-solutions&#34;&gt;Ancient solutions&lt;/h2&gt;
&lt;p&gt;An ancient solution to Ricci flow is a solution that is defined for all time before, say, time $t = 0$.
An example is provided by the shrinking spheres discussed before.
Any sphere has an ancestry reaching back forever, comprising larger and larger spheres as we look further backwards in time.
A more trivial example is the stationary plane: a flat metric is unchanging over time, since the right hand side of the Ricci flow equation is 0.
Certainly such a flow exists for all time, forwards and backwards.
Another important example is the &lt;em&gt;cigar&lt;/em&gt;.
It can be pictured as a tube that extends infinitely in one direction and has a rounded (though not hemispherical) tip.
The almost-flat parts of the manifold, along the cylinder, barely move under the flow, but the curved tip &amp;ldquo;burns away&amp;rdquo; as time goes on.
Explicitly, the cigar is $(\R^2, g)$, with $g$ given in geodesic polar coordinates by
$$ ds^2 + \tanh^2 s , d \theta^2. $$
The rescaling process described in the last section involves scaling the backwards time-domain of the flow to $-\infty$, so singularity models are always ancient solutions (although the converse of this isn&amp;rsquo;t true).&lt;/p&gt;
&lt;h2 id=&#34;classification-of-2-dimensional-ancient-solutions-and-beyond&#34;&gt;Classification of 2-dimensional ancient solutions and beyond&lt;/h2&gt;
&lt;p&gt;We can use the maximum principle mentioned previously to show that ancient solutions have non-negative curvature.
Then by the strong maximum principle, a solution must either have strictly positive curvature everywhere or must be a quotient of the stationary plane (i.e. a flat manifold, the most trivial solution to Ricci flow).
Then the only strictly positively curved ancient solutions are the shrinking spheres, the cigars, and the King-Rosenau solutions, which are sort of like compact versions of the cigars.
This classification was achievd through various papers and somewhat technical analysis.&lt;/p&gt;
&lt;p&gt;Certain techniques in 1-dimensional mean curvature flow (aka curve shortening flow) can be applied to Ricci flow on surfaces.
Recently, Bourni, Langford, and Tinaglia have classified the convex ancient solutions to curve shortening flow.
My project aims to re-prove the classification of ancient Ricci flows on surfaces using the more geometric methods used in this classification.
I also hope to apply some of the methods we learn to classification of solutions in higher dimensions, or possibly classification of solutions to related flows, such as the KÃ¤hler-Ricci flow.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
